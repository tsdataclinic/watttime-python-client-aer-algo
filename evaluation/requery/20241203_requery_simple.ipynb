{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = os.getenv(\"HOME\")\n",
    "os.chdir(f\"{PATH}/watttime-python-client-aer-algo\")\n",
    "\n",
    "import pandas as pd\n",
    "import evaluation.eval_framework as evu\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import evaluation.metrics as m\n",
    "from datetime import timedelta\n",
    "\n",
    "import random\n",
    "import math\n",
    "from watttime import WattTimeForecast, WattTimeHistorical\n",
    "import data.s3 as s3u\n",
    "import importlib\n",
    "import watttime.api as wt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "username = os.getenv(\"WATTTIME_USER\")\n",
    "password = os.getenv(\"WATTTIME_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = s3u.s3_utils()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Details\n",
    "- 2024 dates only in non-tz aware local time.\n",
    "- 1000 users\n",
    "- sanity check on 9 current regions + 9 randomly selected other regions\n",
    "- set of requery increments to test: none, 5,15,60,180\n",
    "- charging windows of lengths 3,6,12 hours\n",
    "- Charge needed at least 45 minutes (25% of smallest window)\n",
    "\n",
    "## Prepared forecast data\n",
    "- already converted to UTC for region specific files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_req = s3.load_csvdataframe(\"requery_data/20241203_1k_synth_users_96_days.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"PJM_CHICAGO\"\n",
    "\n",
    "def sanitize_time_needed(x,y):\n",
    "    return int(math.ceil(min(x, y) / 300.0) * 5)\n",
    "\n",
    "def sanitize_total_intervals(x):\n",
    "    return math.ceil(x)\n",
    "\n",
    "\n",
    "def load_forecast_file(region):\n",
    "    full_forecast = s3.load_parquetdataframe(\n",
    "    f\"complete_2024_forecast_history/{region}.parquet\"\n",
    "    ).drop_duplicates()\n",
    "\n",
    "    full_forecast[\"point_time\"] = pd.to_datetime(\n",
    "    full_forecast[\"point_time\"], utc=True\n",
    "    )\n",
    "\n",
    "    return full_forecast\n",
    "\n",
    "def load_history_file(region):\n",
    "    return s3.load_parquetdataframe(f\"complete_2024_actual_history/{region}.parquet\").drop_duplicates()\n",
    "\n",
    "\n",
    "def prepare_set_of_historic_actuals(\n",
    "        full_history,\n",
    "        start_time,\n",
    "        end_time\n",
    "        ):\n",
    "\n",
    "        moer_list = full_history.loc[\n",
    "                (full_history[\"point_time\"] >= start_time - timedelta(minutes=5)) &\n",
    "                (full_history[\"point_time\"] <= end_time - timedelta(minutes=5))\n",
    "                ]\n",
    "        return moer_list\n",
    "\n",
    "def prepare_set_of_forecasts(\n",
    "                forecasts,\n",
    "                start_time,\n",
    "                end_time,\n",
    "                increment\n",
    "    ):\n",
    "        inc_times = pd.date_range(\n",
    "            start_time,\n",
    "            end_time,\n",
    "            freq=timedelta(minutes=increment),\n",
    "        ).tolist()\n",
    "\n",
    "        moer_list = [\n",
    "            forecasts.loc[\n",
    "            forecasts[\"generated_at\"] == timestamp].sort_values(by=[\"point_time\"], ascending=True)\n",
    "            for timestamp in inc_times\n",
    "        ]\n",
    "\n",
    "        return moer_list\n",
    "\n",
    "def get_recalculating_optimizer_results(\n",
    "    region: str,\n",
    "    moer_list: pd.DataFrame,\n",
    "    start_time: datetime,\n",
    "    end_time: datetime,\n",
    "    usage_power_kw,\n",
    "    time_needed,\n",
    "    increment,\n",
    "    charge_per_interval = None,\n",
    "):\n",
    "    \n",
    "    if charge_per_interval is None:\n",
    "        wt_opt_rc = wt.RecalculatingWattTimeOptimizer(\n",
    "            region=region,\n",
    "            watttime_username=username,\n",
    "            watttime_password=password,\n",
    "            usage_time_required_minutes=time_needed,\n",
    "            usage_power_kw=usage_power_kw,\n",
    "            optimization_method=\"auto\"\n",
    "            )\n",
    "    else:\n",
    "        wt_opt_rc = wt.RecalculatingWattTimeOptimizerWithContiguity(\n",
    "            username,\n",
    "            password,\n",
    "            region,\n",
    "            usage_time_required_minutes=time_needed,\n",
    "            usage_power_kw=usage_power_kw,\n",
    "            optimization_method='auto',\n",
    "            charge_per_interval=charge_per_interval,\n",
    "        )\n",
    "\n",
    "    new_start_time = start_time\n",
    "    while new_start_time < end_time:\n",
    "        for fcst_data in moer_list:\n",
    "            new_start_time = pd.Timestamp(fcst_data[\"point_time\"].min())\n",
    "            wt_opt_rc.get_new_schedule(\n",
    "                    new_start_time=new_start_time,\n",
    "                    new_end_time=end_time,\n",
    "                    curr_fcst_data=fcst_data\n",
    "                )\n",
    "    print(\"combining schedules\")\n",
    "    usage_plan = wt_opt_rc.get_combined_schedule(end_time=end_time)\n",
    "    usage_plan[\"requery_increment\"] = increment\n",
    "\n",
    "    return usage_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanitize input data\n",
    "df_req[\"sanitize_intervals_plugged_in\"] = df_req.apply(lambda x: sanitize_total_intervals(x.total_intervals_plugged_in), axis=1)\n",
    "df_req[\"sanitize_time_needed\"] = df_req.apply(lambda x: sanitize_time_needed(x.total_seconds_to_95, x.length_of_session_in_seconds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data = df_req.sample(25).copy()\n",
    "synth_data.session_start_time = pd.to_datetime(synth_data.session_start_time)\n",
    "synth_data.session_end_time = pd.to_datetime(synth_data.session_end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_regions = [\n",
    "    \"SPP_TX\",\n",
    "    \"ERCOT_EASTTX\",\n",
    "    \"FPL\",\n",
    "    \"SOCO\",\n",
    "    \"PJM_CHICAGO\",\n",
    "    \"LDWP\",\n",
    "    \"PJM_DC\",\n",
    "    \"NYISO_NYC\",\n",
    "]\n",
    "\n",
    "random_regions = [\n",
    "    'PACE',\n",
    "    'PNM',\n",
    "    'MISO_INDIANAPOLIS',\n",
    "    'WALC',\n",
    "    'ERCOT_AUSTIN',\n",
    "    'SPP_KANSAS',\n",
    "    'ISONE_VT',\n",
    "    'SPP_SIOUX',\n",
    "    'SC'\n",
    "]\n",
    "\n",
    "regions = original_regions+random_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "regions = [\"PJM_CHICAGO\"]\n",
    "for region in regions:\n",
    "\n",
    "    full_forecast = load_forecast_file(region)\n",
    "    full_history = load_history_file(region)\n",
    "\n",
    "    all_synth_users_list = []\n",
    "    bad_dat = []\n",
    "    increments = [120,240]\n",
    "    for i in range(0,synth_data.shape[0]):\n",
    "        try:\n",
    "            loc_num = i\n",
    "            time_zone = evu.get_timezone_from_dict(region)                    \n",
    "            start_time_utc = pd.Timestamp(evu.convert_to_utc(synth_data.iloc[loc_num]['session_start_time'].round('5min') , time_zone))\n",
    "            end_time_utc = pd.Timestamp(evu.convert_to_utc(synth_data.iloc[loc_num]['session_end_time'].round('5min'), time_zone))\n",
    "            time_needed = synth_data.iloc[loc_num][\"sanitize_time_needed\"]\n",
    "            total_intervals_plugged_in = synth_data.iloc[loc_num][\"sanitize_intervals_plugged_in\"]\n",
    "            usage_power_kw = float(synth_data.iloc[loc_num][\"power_output_rate\"])\n",
    "            user_type = synth_data.iloc[loc_num][\"user_type\"]\n",
    "            optimization_method = \"auto\"\n",
    "            print(user_type)\n",
    "            \n",
    "            results_dfs = []\n",
    "            for increment in increments:\n",
    "                try:\n",
    "                    print(increment)\n",
    "                    moer_list = prepare_set_of_forecasts(\n",
    "                    forecasts=full_forecast,\n",
    "                    increment=increment,\n",
    "                    start_time=start_time_utc,\n",
    "                    end_time=end_time_utc\n",
    "                    )\n",
    "\n",
    "                    results = get_recalculating_optimizer_results(\n",
    "                    region=region,\n",
    "                    moer_list = moer_list,\n",
    "                    start_time=start_time_utc,\n",
    "                    end_time=end_time_utc,\n",
    "                    time_needed=time_needed,\n",
    "                    usage_power_kw=usage_power_kw,\n",
    "                    increment=increment\n",
    "                    )\n",
    "\n",
    "                    results_dfs.append(results)\n",
    "                except:\n",
    "                    no_go = synth_data.iloc[i].copy(deep=True)\n",
    "                    no_go[\"increment\"] = increment\n",
    "                    bad_dat.append(no_go)\n",
    "                    continue\n",
    "\n",
    "            analysis = pd.concat(results_dfs)\n",
    "\n",
    "            # baseline + ideal\n",
    "            moer_list_actuals = prepare_set_of_historic_actuals(\n",
    "                full_history=full_history,\n",
    "                start_time=start_time_utc,\n",
    "                end_time=end_time_utc\n",
    "                )\n",
    "            \n",
    "            ideal = evu.get_schedule_and_cost_api(\n",
    "                    total_time_horizon = total_intervals_plugged_in,\n",
    "                    usage_power_kw=usage_power_kw,\n",
    "                    time_needed=time_needed,\n",
    "                    optimization_method=\"auto\",\n",
    "                    moer_data=moer_list_actuals,\n",
    "                    charge_per_interval=None\n",
    "                    )\n",
    "            ideal[\"requery_increment\"] = \"ideal\"\n",
    "\n",
    "            baseline = evu.get_schedule_and_cost_api(\n",
    "                    total_time_horizon = total_intervals_plugged_in,\n",
    "                    usage_power_kw=usage_power_kw,\n",
    "                    time_needed=time_needed,\n",
    "                    optimization_method=\"baseline\",\n",
    "                    moer_data=moer_list_actuals,\n",
    "                    charge_per_interval=None\n",
    "                    )\n",
    "            baseline[\"requery_increment\"] = \"baseline\"\n",
    "\n",
    "            analysis_full = pd.concat([analysis,baseline,ideal]).merge(moer_list_actuals, on=\"point_time\", how=\"left\")\n",
    "            analysis_full[\"emissions_co2e_lb_actual\"] = analysis_full[\"value\"]*analysis_full[\"energy_usage_mwh\"]\n",
    "            analysis_full[\"user_type\"] = user_type\n",
    "            all_synth_users_list.append(analysis_full)\n",
    "            analysis = pd.concat(all_synth_users_list).drop_duplicates(subset=[\"user_type\",\"requery_increment\",\"point_time\"])\n",
    "            s3.store_csvdataframe(analysis,f\"results/analysis_requery_20241209_{region}.csv\")\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_dat_df = pd.concat(bad_dat, axis=1).T\n",
    "s3.store_csvdataframe(bad_dat_df,f\"results/bad_dat_20241210_{region}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_time</th>\n",
       "      <th>pred_moer</th>\n",
       "      <th>usage</th>\n",
       "      <th>emissions_co2e_lb</th>\n",
       "      <th>energy_usage_mwh</th>\n",
       "      <th>requery_increment</th>\n",
       "      <th>value</th>\n",
       "      <th>region</th>\n",
       "      <th>emissions_co2e_lb_actual</th>\n",
       "      <th>user_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-11 04:55:00+00:00</td>\n",
       "      <td>1180.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>PJM_CHICAGO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>r35.9975_tc68_avglc28185_sdlc7446_contFalse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-11 05:00:00+00:00</td>\n",
       "      <td>1180.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>PJM_CHICAGO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>r35.9975_tc68_avglc28185_sdlc7446_contFalse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-11 05:05:00+00:00</td>\n",
       "      <td>1174.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>PJM_CHICAGO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>r35.9975_tc68_avglc28185_sdlc7446_contFalse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-11 05:10:00+00:00</td>\n",
       "      <td>1167.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>PJM_CHICAGO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>r35.9975_tc68_avglc28185_sdlc7446_contFalse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-11 05:15:00+00:00</td>\n",
       "      <td>1172.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>PJM_CHICAGO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>r35.9975_tc68_avglc28185_sdlc7446_contFalse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 point_time  pred_moer  usage  emissions_co2e_lb  \\\n",
       "0 2024-03-11 04:55:00+00:00     1180.2    0.0                0.0   \n",
       "1 2024-03-11 05:00:00+00:00     1180.2    0.0                0.0   \n",
       "2 2024-03-11 05:05:00+00:00     1174.7    0.0                0.0   \n",
       "3 2024-03-11 05:10:00+00:00     1167.3    0.0                0.0   \n",
       "4 2024-03-11 05:15:00+00:00     1172.5    0.0                0.0   \n",
       "\n",
       "   energy_usage_mwh requery_increment   value       region  \\\n",
       "0               0.0               120  1197.0  PJM_CHICAGO   \n",
       "1               0.0               120  1209.0  PJM_CHICAGO   \n",
       "2               0.0               120  1171.0  PJM_CHICAGO   \n",
       "3               0.0               120  1182.0  PJM_CHICAGO   \n",
       "4               0.0               120  1200.0  PJM_CHICAGO   \n",
       "\n",
       "   emissions_co2e_lb_actual                                    user_type  \n",
       "0                       0.0  r35.9975_tc68_avglc28185_sdlc7446_contFalse  \n",
       "1                       0.0  r35.9975_tc68_avglc28185_sdlc7446_contFalse  \n",
       "2                       0.0  r35.9975_tc68_avglc28185_sdlc7446_contFalse  \n",
       "3                       0.0  r35.9975_tc68_avglc28185_sdlc7446_contFalse  \n",
       "4                       0.0  r35.9975_tc68_avglc28185_sdlc7446_contFalse  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_type                                    requery_increment\n",
       "r21.505_tc108_avglc20529_sdlc7125_contFalse  120                  60.834061\n",
       "                                             baseline             60.269555\n",
       "                                             ideal                59.855583\n",
       "r21.59_tc75_avglc20714_sdlc7568_contFalse    120                  33.185629\n",
       "                                             240                  35.366219\n",
       "                                                                    ...    \n",
       "r36.805_tc102_avglc22080_sdlc7685_contFalse  baseline             49.422981\n",
       "                                             ideal                45.386699\n",
       "r38.08_tc77_avglc29445_sdlc7309_contFalse    120                  39.441360\n",
       "                                             baseline             41.427867\n",
       "                                             ideal                28.137947\n",
       "Name: emissions_co2e_lb_actual, Length: 68, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.groupby([\"user_type\",\"requery_increment\"])[\"emissions_co2e_lb_actual\"].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watttime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
