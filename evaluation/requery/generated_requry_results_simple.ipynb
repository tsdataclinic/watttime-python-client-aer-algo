{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(f\"/home/{os.getlogin()}/watttime-python-client-aer-algo\")\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pytz import UTC, timezone\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import concurrent.futures\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "from watttime import WattTimeForecast, WattTimeHistorical, RecalculatingWattTimeOptimizer\n",
    "\n",
    "import data.s3 as s3u\n",
    "import evaluation.eval_framework as efu\n",
    "from plotnine import *\n",
    "\n",
    "username = os.getenv(\"WATTTIME_USER\")\n",
    "password = os.getenv(\"WATTTIME_PASSWORD\")\n",
    "\n",
    "actual_data = WattTimeHistorical(username, password)\n",
    "hist_data = WattTimeForecast(username, password)\n",
    "\n",
    "s3 = s3u.s3_utils()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date_with_time(start, end):\n",
    "\n",
    "    time_between_dates = end - start\n",
    "    random_number_of_seconds = random.randint(0, int(time_between_dates.total_seconds()))\n",
    "    random_date = start + timedelta(seconds=random_number_of_seconds)\n",
    "    \n",
    "    random_hour = random.randint(0, 23)\n",
    "    random_minute = random.randint(0, 59)\n",
    "    \n",
    "    random_date_with_time = random_date.replace(hour=random_hour, minute=random_minute)\n",
    "    return pd.to_datetime(random_date_with_time, utc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_requery_sim(region, full_forecast, full_history, increments, start_time, end_time, usage_power_kw, time_needed, method = \"simple\"):\n",
    "\n",
    "    results = {}\n",
    "    all_relevant_forecasts = full_forecast.set_index(\"generated_at\")[start_time - timedelta(minutes = 5):end_time].reset_index()\n",
    "    all_relevant_forecasts = all_relevant_forecasts.set_index(\"generated_at\")[start_time - timedelta(minutes = 5):end_time]\n",
    "    baseline_forecast = all_relevant_forecasts.loc[all_relevant_forecasts.index.min()].reset_index()\n",
    "    schedules = []\n",
    "\n",
    "    ideal = efu.get_schedule_and_cost_api_requerying(region = region,\n",
    "                                        usage_power_kw = usage_power_kw,\n",
    "                                        time_needed = time_needed,\n",
    "                                        start_time = start_time,\n",
    "                                        end_time = end_time, \n",
    "                                        optimization_method=\"simple\",\n",
    "                                        moer_list = [full_history.set_index(\"point_time\")[start_time - timedelta(minutes = 5):end_time].reset_index()]).reset_index().rename({\"pred_moer\" : \"actual_moer\"}, axis = 1)\n",
    "\n",
    "    results[\"ideal_emissions\"] = round(ideal[\"emissions_co2e_lb\"].sum(), 2)\n",
    "    ideal[\"increment\"] = \"Ideal\"\n",
    "    ideal[\"pred_moer\"] = ideal[\"actual_moer\"]\n",
    "    ideal[\"actual_emissions\"] = ideal[\"actual_moer\"]*ideal[\"energy_usage_mwh\"]\n",
    "    schedules.append(ideal)\n",
    "\n",
    "\n",
    "    baseline = efu.get_schedule_and_cost_api_requerying(region = region,\n",
    "                                        usage_power_kw = usage_power_kw,\n",
    "                                        time_needed = time_needed,\n",
    "                                        start_time = start_time,\n",
    "                                        end_time = end_time, \n",
    "                                        optimization_method=\"baseline\",\n",
    "                                        moer_list = [baseline_forecast]).reset_index()\n",
    "\n",
    "    baseline = baseline.merge(ideal[[\"point_time\", \"actual_moer\"]])\n",
    "\n",
    "    baseline[\"increment\"] = \"Baseline\"\n",
    "    baseline[\"actual_emissions\"] = baseline[\"actual_moer\"]*baseline[\"energy_usage_mwh\"]\n",
    "\n",
    "    schedules.append(baseline)\n",
    "\n",
    "    results[\"baseline_predicted_emissions\"] = round(baseline[\"emissions_co2e_lb\"].sum(), 2)\n",
    "    results[\"baseline_actual_emissions\"] = round((baseline[\"actual_moer\"]*baseline[\"energy_usage_mwh\"]).sum(), 2)\n",
    "\n",
    "    no_requery = efu.get_schedule_and_cost_api_requerying(region = region,\n",
    "                                        usage_power_kw = usage_power_kw,\n",
    "                                        time_needed = time_needed,\n",
    "                                        start_time = start_time,\n",
    "                                        end_time = end_time, \n",
    "                                        optimization_method=method,\n",
    "                                        moer_list = [baseline_forecast]).reset_index()\n",
    "\n",
    "    no_requery = no_requery.merge(ideal[[\"point_time\", \"actual_moer\"]])\n",
    "    no_requery[\"increment\"] = \"No requery\"\n",
    "    no_requery[\"actual_emissions\"] = no_requery[\"actual_moer\"]*no_requery[\"energy_usage_mwh\"]\n",
    "    schedules.append(no_requery)\n",
    "\n",
    "    results[\"no_requery_predicted_emissions\"] = round(no_requery[\"emissions_co2e_lb\"].sum(), 2)\n",
    "    results[\"no_requery_actual_emissions\"] = round((no_requery[\"actual_moer\"]*no_requery[\"energy_usage_mwh\"]).sum(), 2)\n",
    "\n",
    "\n",
    "\n",
    "    for increment in increments:\n",
    "        inc_times = pd.date_range(all_relevant_forecasts.index.min(), all_relevant_forecasts.index.max(), freq=timedelta(minutes=increment))\n",
    "        moer_list = [all_relevant_forecasts.loc[timestamp].reset_index() for timestamp in inc_times]\n",
    "\n",
    "        print(len(moer_list))\n",
    "\n",
    "        schedule = efu.get_schedule_and_cost_api_requerying(region = region,\n",
    "                                        usage_power_kw = usage_power_kw,\n",
    "                                        time_needed = time_needed,\n",
    "                                        start_time = start_time,\n",
    "                                        end_time = end_time, \n",
    "                                        optimization_method=method,\n",
    "                                        moer_list = moer_list).reset_index()\n",
    "        \n",
    "        \n",
    "        schedule = schedule.merge(ideal[[\"point_time\", \"actual_moer\"]])\n",
    "        schedule[\"actual_emissions\"] = schedule[\"actual_moer\"]*schedule[\"energy_usage_mwh\"]\n",
    "        schedule[\"increment\"] = f\"Requery {increment} minutes\"\n",
    "        schedules.append(schedule)\n",
    "\n",
    "\n",
    "        results[f\"schedule_predicted_emissions_requery_{increment}\"] = round(schedule[\"emissions_co2e_lb\"].sum(), 2)\n",
    "        results[f\"schedule_actual_emissions_requery_{increment}\"] = round((schedule[\"actual_moer\"]*schedule[\"energy_usage_mwh\"]).sum(), 2)\n",
    "\n",
    "    increment_order = [f\"Requery {increment} minutes\" for increment in increments]\n",
    "    order = [\"Ideal\", \"Baseline\", \"No requery\"] + increment_order[::-1]\n",
    "    full_schedules = pd.concat(schedules)\n",
    "    full_schedules[\"increment\"] = pd.Categorical(full_schedules[\"increment\"], order, ordered = True)\n",
    "\n",
    "    return full_schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic paramaters to get simple data. Will eventually be expanded to the synthetic users\n",
    "\n",
    "increments = [5, 15, 30, 60, 120, 180, 240, 360]\n",
    "start_time = random_date_with_time(datetime(2023, 1, 1), datetime(2023, 12, 31))\n",
    "end_time = start_time + timedelta(hours = 12)\n",
    "usage_power_kw = 2\n",
    "time_needed = 180\n",
    "\n",
    "\n",
    "regions = [\n",
    " 'CAISO_NORTH',\n",
    " 'SPP_TX',\n",
    " 'ERCOT_EASTTX',\n",
    " 'FPL',\n",
    " 'SOCO',\n",
    " 'PJM_CHICAGO',\n",
    " 'LDWP',\n",
    " 'PJM_DC',\n",
    " 'NYISO_NYC'\n",
    "]\n",
    "\n",
    "dates = [pd.to_datetime(random_date_with_time(datetime(2023, 1, 1), datetime(2023, 12, 31))) for i in range(0, 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAISO_NORTH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 72/1000 [18:49<2:31:37,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-07-03 06:10:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 242/1000 [1:01:39<2:53:21, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 368/1000 [1:36:20<2:22:18, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-09-03 13:45:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 447/1000 [1:56:58<2:13:49, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 593/1000 [2:34:52<1:11:59, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-05-24 04:05:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 676/1000 [2:58:44<57:22, 10.63s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-01-20 16:15:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 810/1000 [3:32:24<34:43, 10.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 879/1000 [3:49:58<19:41,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-09-03 13:45:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 883/1000 [3:50:51<20:04, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-06-02 03:50:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 963/1000 [4:11:14<06:49, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [4:20:59<00:00, 15.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPP_TX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 72/1000 [17:15<2:32:18,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-07-03 06:10:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 242/1000 [36:18<1:15:30,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 447/1000 [57:46<55:02,  5.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 593/1000 [1:12:48<31:25,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-05-24 04:05:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 810/1000 [1:35:05<18:25,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 883/1000 [1:42:33<08:59,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-06-02 03:50:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 963/1000 [1:50:46<02:53,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:54:40<00:00,  6.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERCOT_EASTTX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 72/1000 [07:24<1:12:10,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-07-03 06:10:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 242/1000 [25:05<1:15:18,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 447/1000 [46:08<54:11,  5.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 810/1000 [1:23:24<18:17,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 883/1000 [1:30:43<08:54,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-06-02 03:55:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 963/1000 [1:38:49<02:49,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:42:36<00:00,  6.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [01:08<1:14:56,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-11-03 11:10:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 72/1000 [07:11<1:12:08,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-07-03 06:10:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 242/1000 [24:35<1:12:32,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 447/1000 [45:33<53:30,  5.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 495/1000 [50:26<39:05,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-09-03 04:55:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 810/1000 [1:22:32<18:21,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 879/1000 [1:29:29<09:09,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-09-03 04:55:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 883/1000 [1:29:49<08:11,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-06-02 03:55:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:41:46<00:00,  6.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 72/1000 [07:15<1:10:35,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-07-03 06:10:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 242/1000 [24:48<1:12:29,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 447/1000 [45:47<54:36,  5.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 810/1000 [1:23:03<18:16,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 883/1000 [1:30:25<08:56,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-06-02 03:55:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:42:27<00:00,  6.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PJM_CHICAGO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 72/1000 [07:19<1:09:21,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-07-03 06:10:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 242/1000 [24:43<1:13:02,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 295/1000 [30:03<53:33,  4.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 368/1000 [37:26<48:16,  4.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-09-03 13:45:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 447/1000 [45:29<53:26,  5.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 593/1000 [1:00:19<31:25,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2023-05-24 04:05:00+0000', tz='UTC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 810/1000 [1:22:32<18:21,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 868/1000 [1:28:28<13:50,  6.29s/it]"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for region in regions:\n",
    "    print(region)\n",
    "    full_forecast = s3.load_parquetdataframe(f\"complete_2023_forecast_history/{region}.parquet\").drop_duplicates()\n",
    "    full_forecast['point_time'] = pd.to_datetime(full_forecast['point_time'], utc=True)\n",
    "    full_history = s3.load_parquetdataframe(f\"complete_2023_actual_history/{region}.parquet\").drop_duplicates()\n",
    "\n",
    "    for date in tqdm(dates):\n",
    "        try:\n",
    "            with contextlib.redirect_stdout(io.StringIO()), warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)  \n",
    "                schedules = full_requery_sim(region, full_forecast, full_history, increments, date, date + timedelta(hours = 12), usage_power_kw, time_needed, method = \"simple\")\n",
    "            schedules[\"init_time\"] = date\n",
    "            schedules[\"region\"] = region\n",
    "            out.append(schedules)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "out_df = pd.concat(out)\n",
    "s3.store_parquetdataframe(out_df, f'historical_requery_sim_1000_simple_fit.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
