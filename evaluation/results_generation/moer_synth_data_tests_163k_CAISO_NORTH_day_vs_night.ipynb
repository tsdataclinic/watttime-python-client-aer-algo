{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(f\"/home/{os.getlogin()}/watttime-python-client-aer-algo\")\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pytz\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "\n",
    "from watttime import WattTimeForecast, WattTimeHistorical\n",
    "\n",
    "import optimizer.s3 as s3u\n",
    "import evaluation.eval_framework as efu\n",
    "\n",
    "import watttime.shared_anniez.alg.optCharger as optC\n",
    "import watttime.shared_anniez.alg.moer as Moer\n",
    "\n",
    "\n",
    "username = os.getenv(\"WATTTIME_USER\")\n",
    "password = os.getenv(\"WATTTIME_PASSWORD\")\n",
    "\n",
    "actual_data = WattTimeHistorical(username, password)\n",
    "hist_data = WattTimeForecast(username, password)\n",
    "\n",
    "s3 = s3u.s3_utils()\n",
    "key = \"20240726_1k_synth_users_163_days.csv\"\n",
    "generated_data = s3.load_csvdataframe(file=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic user data\n",
    "\n",
    "region = \"CAISO_NORTH\"\n",
    "\n",
    "synth_data = generated_data.copy(deep=True)\n",
    "synth_data[\"session_start_time\"] = pd.to_datetime(synth_data[\"session_start_time\"])\n",
    "synth_data[\"unplug_time\"] = pd.to_datetime(synth_data[\"unplug_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cached version of the get_*_data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORICAL_ACTUAL_CACHE = pickle.loads(s3u.s3_utils().load_file(f\"{region}_actual.pkl\"))\n",
    "HISTORICAL_FORECAST_CACHE = pickle.loads(s3u.s3_utils().load_file(f\"{region}_fore.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_fcst_data_cached(session_start_time, horizon, region):\n",
    "    time_zone = efu.get_timezone_from_dict(region)\n",
    "    session_start_time_utc = pd.Timestamp(\n",
    "        efu.convert_to_utc(session_start_time, time_zone)\n",
    "    )\n",
    "    date = session_start_time.date()\n",
    "    if (region, date) not in HISTORICAL_FORECAST_CACHE.keys():\n",
    "        print(type(date), date)\n",
    "        start = pd.to_datetime(date)\n",
    "        end = pd.to_datetime(date) + pd.Timedelta(\"1d\")\n",
    "        HISTORICAL_FORECAST_CACHE[(region, date)] = (\n",
    "            hist_data.get_historical_forecast_pandas(\n",
    "                start - pd.Timedelta(\"9h\"),\n",
    "                end + pd.Timedelta(\"9h\"),\n",
    "                region,\n",
    "            )\n",
    "        )\n",
    "    cache = HISTORICAL_FORECAST_CACHE[(region, date)]\n",
    "\n",
    "    # make this match efu.get_historical_fsct_data\n",
    "    generated_at_times = cache[\"generated_at\"].unique()\n",
    "    generated_at = max([t for t in generated_at_times if t < session_start_time_utc])\n",
    "    df = cache[cache[\"generated_at\"] == generated_at].copy()\n",
    "    return df.iloc[: math.ceil(horizon / 12) * 12]\n",
    "\n",
    "\n",
    "def get_historical_actual_data_cached(session_start_time, horizon, region):\n",
    "    time_zone = efu.get_timezone_from_dict(region)\n",
    "    session_start_time_utc = pd.Timestamp(\n",
    "        efu.convert_to_utc(session_start_time, time_zone)\n",
    "    )\n",
    "    date = session_start_time.date()\n",
    "\n",
    "    if (region, date) not in HISTORICAL_ACTUAL_CACHE.keys():\n",
    "        start = pd.to_datetime(date)\n",
    "        end = pd.to_datetime(date) + pd.Timedelta(\"2d\")\n",
    "        HISTORICAL_ACTUAL_CACHE[(region, date)] = actual_data.get_historical_pandas(\n",
    "            start - pd.Timedelta(\"9h\"),\n",
    "            end + pd.Timedelta(\"9h\"),\n",
    "            region,\n",
    "        )\n",
    "    cache = HISTORICAL_ACTUAL_CACHE[(region, date)]\n",
    "\n",
    "    t_start = max(\n",
    "        [t for t in cache[\"point_time\"].unique() if t < session_start_time_utc]\n",
    "    )\n",
    "    df = cache[cache[\"point_time\"] >= t_start].copy()\n",
    "    return df.iloc[: math.ceil(horizon / 12) * 12 + 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_emission(moer, schedule):\n",
    "    x = np.array(schedule).flatten()\n",
    "    return np.dot(moer[: x.shape[0]], x)\n",
    "\n",
    "\n",
    "def generate_results(synth_data):\n",
    "    print(\"Get the data: forecast\")\n",
    "    synth_data[\"moer_data\"] = synth_data.apply(\n",
    "        lambda x: get_historical_fcst_data_cached(\n",
    "            x.session_start_time, math.ceil(x.total_intervals_plugged_in), region=region\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    print(\"Get the data: actual\")\n",
    "    synth_data[\"moer_data_actual\"] = synth_data.apply(\n",
    "        lambda x: get_historical_actual_data_cached(\n",
    "            x.session_start_time, math.ceil(x.total_intervals_plugged_in), region=region\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    print(\"Generate the baeline schedule training on the actual\")\n",
    "    synth_data[\"charger_baseline_actual\"] = synth_data.apply(\n",
    "        lambda x: efu.get_schedule_and_cost(\n",
    "            x.MWh_fraction,\n",
    "            x.charged_kWh_actual / 1000,\n",
    "            math.ceil(\n",
    "                x.total_intervals_plugged_in\n",
    "            ),  # will throw an error if the plug in time is too shart to reach full charge, should soften to a warning\n",
    "            x.moer_data_actual,\n",
    "            asap=True,\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    print(\"Get the baseline schedule\")\n",
    "    synth_data[\"baseline_charging_schedule\"] = synth_data[\n",
    "        \"charger_baseline_actual\"\n",
    "    ].apply(lambda x: x.get_schedule())\n",
    "\n",
    "    print(\"Get the baseline actual emissions\")\n",
    "    synth_data[\"baseline_actual_emissions\"] = synth_data[\n",
    "        \"charger_baseline_actual\"\n",
    "    ].apply(lambda x: x.get_total_emission())\n",
    "\n",
    "    print(\"Generate the simple schedule, training on the forecast\")\n",
    "    synth_data[\"charger_simple_forecast\"] = synth_data.apply(\n",
    "        lambda x: efu.get_schedule_and_cost(\n",
    "            x.MWh_fraction,\n",
    "            x.charged_kWh_actual / 1000,\n",
    "            math.ceil(\n",
    "                x.total_intervals_plugged_in\n",
    "            ),  # will throw an error if the plug in time is too shart to reach full charge, should soften to a warning\n",
    "            x.moer_data,\n",
    "            asap=False,\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    synth_data[\"simple_charging_schedule\"] = synth_data[\n",
    "        \"charger_simple_forecast\"\n",
    "    ].apply(lambda x: x.get_schedule())\n",
    "\n",
    "    print(\"Get the estimated emissions, e.g. evaluating on the forecast\")\n",
    "    synth_data[\"simple_estimated_emissions\"] = synth_data[\n",
    "        \"charger_simple_forecast\"\n",
    "    ].apply(lambda x: x.get_total_emission())\n",
    "\n",
    "    print(\n",
    "        \"Generate the simple schedule training on the actual: this is the ideal schedule\"\n",
    "    )\n",
    "    synth_data[\"charger_simple_actual\"] = synth_data.apply(\n",
    "        lambda x: efu.get_schedule_and_cost(\n",
    "            x.MWh_fraction,\n",
    "            x.charged_kWh_actual / 1000,\n",
    "            math.ceil(\n",
    "                x.total_intervals_plugged_in\n",
    "            ),  # will throw an error if the plug in time is too shart to reach full charge, should soften to a warning\n",
    "            x.moer_data_actual,\n",
    "            asap=False,\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    synth_data[\"simple_actual_charging_schedule\"] = synth_data[\n",
    "        \"charger_simple_actual\"\n",
    "    ].apply(lambda x: x.get_schedule())\n",
    "\n",
    "    synth_data[\"simple_ideal_emissions\"] = synth_data[\"charger_simple_actual\"].apply(\n",
    "        lambda x: x.get_total_emission()\n",
    "    )\n",
    "\n",
    "    print(\"MOER - No Optimization - Actual Emissions\")\n",
    "    synth_data[\"simple_actual_emissions\"] = synth_data.apply(\n",
    "        lambda x: get_total_emission(\n",
    "            x.moer_data_actual[\"value\"],\n",
    "            x.simple_charging_schedule,\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    cols = [\n",
    "        \"user_type\",\n",
    "        \"power_output_rate\",\n",
    "        \"distinct_dates\",\n",
    "        \"session_start_time\",\n",
    "        \"total_intervals_plugged_in\",\n",
    "        \"charged_kWh_actual\",\n",
    "        \"MWh_fraction\",\n",
    "        \"simple_actual_emissions\",\n",
    "        \"baseline_actual_emissions\",\n",
    "        \"simple_estimated_emissions\",\n",
    "        \"simple_ideal_emissions\",\n",
    "    ]\n",
    "\n",
    "    return synth_data[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%capture \n",
    "# the %%capture cellmagic stops all the print messages being shown\n",
    "results_data = generate_results(synth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "synth_data_daytime = synth_data.copy()\n",
    "synth_data_daytime[\"session_start_time\"] = synth_data_daytime[\n",
    "    \"session_start_time\"\n",
    "] - pd.Timedelta(hours=12)\n",
    "\n",
    "results_data_daytime = generate_results(synth_data_daytime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful S3 put_object response. Status - 200\n",
      "Successful S3 put_object response. Status - 200\n"
     ]
    }
   ],
   "source": [
    "s3.store_csvdataframe(\n",
    "    results_data, f\"results/20240818_1k_synth_users_163_days_{region}.csv\"\n",
    ")\n",
    "s3.store_csvdataframe(\n",
    "    results_data_daytime,\n",
    "    f\"results/20240818_1k_synth_users_163_days_{region}_daytime.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard synthetic user data. Total possible emission savings:\n",
      "-85483.50453249615\n",
      "Daytime version of synthetic user data. Total possible emission savings:\n",
      "-614162.1579068066\n"
     ]
    }
   ],
   "source": [
    "results_data[\"largest_possible_difference\"] = (\n",
    "    results_data[\"simple_ideal_emissions\"] - results_data[\"baseline_actual_emissions\"]\n",
    ")\n",
    "print(\"Standard synthetic user data. Total possible emission savings:\")\n",
    "print(results_data[\"largest_possible_difference\"].sum())\n",
    "\n",
    "results_data_daytime[\"largest_possible_difference\"] = (\n",
    "    results_data_daytime[\"simple_ideal_emissions\"]\n",
    "    - results_data_daytime[\"baseline_actual_emissions\"]\n",
    ")\n",
    "print(\"Daytime version of synthetic user data. Total possible emission savings:\")\n",
    "print(results_data_daytime[\"largest_possible_difference\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
